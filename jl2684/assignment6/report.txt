A.  
For labeled data set, I created two scatterplot graphs Population vs. Incidents and Zipcode vs. Incidents and one bargraph Zipcode vs. Incidents. With Zipcode, I don't see any relationship with Incident variables. To confirmed my belief, I have also created a bar graph that shows for each zipcode there is no relationship to incidents - which makes sense because the increase of zipcode number shouldn't have any correlation with incidents, because zipcodes of NYC is all over various values. 

For Population, I see a potential for creating a regressional line and model for prediction. I'm guessing there can be a positive relationship between the population size and incidents. It is also intuitive because if the area has more population, there can be more reports of incidents.  

B. 
After conducting the 10-fold-Cross Validation followings are my results {Order: [[Trial #, R^2, RMSE]]}:   

{1: [[1, 0.61606210571457709, 11249.86779131677], [2, 0.60826740548460401, 13921.42015806943], [3, 0.61013273202713636, 13770.041906455563], [4, 0.60436049866299857, 19372.715430248707], [5, 0.61233982950231225, 12109.639802677772], [6, 0.60943664914677198, 11876.009487459212], [7, 0.60301326861972049, 11086.256101619285], [8, 0.62884790245560673, 14357.82342625679], [9, 0.6138501023263816, 9252.334219875356], [10, 0.6156536216199171, 16103.046296733459]], 
2: [[1, 0.63623401269031921, 10773.595231896588], [2, 0.64046326238030371, 15458.946882178583], [3, 0.63045953194104554, 13236.832263262846], [4, 0.61534855209895034, 17972.39931747538], [5, 0.63723778386625241, 12490.40892813409], [6, 0.63145517972478893, 11672.539881553354], [7, 0.62293851828719737, 10440.060121892833], [8, 0.65567329142833275, 15036.71219826404], [9, 0.63286535250723808, 8464.653819972062], [10, 0.63371968223029673, 15323.895314386187]], 
3: [[1, 0.64520872292768638, 10554.536900070078], [2, 0.6426596335076129, 14464.521482304823], [3, 0.63972549564413361, 13041.817726265304], [4, 0.64174635836544225, 19947.91913427995], [5, 0.64497911873931302, 12081.778411926916], [6, 0.64185929686530863, 11707.375195072174], [7, 0.63173546524095869, 10124.602166384542], [8, 0.66665865672728064, 15145.879610807131], [9, 0.64131791637303792, 8075.460483981748], [10, 0.64142636071016812, 14884.99822316298]], 
4: [[1, 0.64608619900312503, 10557.317834873511], [2, 0.64358804773749656, 15459.606741887275], [3, 0.6409624077151278, 13096.58475787444], [4, 0.64400431016141946, 20084.73437938814], [5, 0.64768735750003326, 12531.442099920228], [6, 0.64263440107666436, 11688.704590021865], [7, 0.63222330023916495, 10051.273752423134], [8, 0.66860250486990902, 15336.27131009546], [9, 0.64235518673431691, 8136.286284942635], [10, 0.64142763446891327, 14875.225922170888]], 

5: [[1, 0.6479108702128914, 10777.703294538289], [2, 0.64547852282214857, 18347.337864231584], [3, 0.64210530805801558, 13118.860956500139], [4, 0.64401200856337371, 20109.91864757658], [5, 0.64897644599321869, 12582.860890557451], [6, 0.64389054655341538, 11747.919869379515], [7, 0.63425084135754606, 10328.952760073153], [8, 0.66890651353579544, 15268.096804200952], [9, 0.64348686419894541, 8194.835852735841], [10, 0.64290855576767414, 14949.939858195734]]}

In order to find the best fitting model, I found the average values of R^2 and RSME for each order. I also created two plot graphs on this data. 

For Order 1, AVG R^2 is 0.612196411556 and AVG RSME is 13309.9154621
For Order 2, AVG R^2 is 0.633639516715 and AVG RSME is 13087.0043959
For Order 3, AVG R^2 is 0.64373170251 and AVG RSME is 13002.8889334
For Order 4, AVG R^2 is 0.644957134951 and AVG RSME is 13181.7447674
For Order 5, AVG R^2 is 0.646192647706 and AVG RSME is 13542.6426798

Based on following observation, I am leaning toward Poloynominal Order 3, since the average RSME value is the smallest while the average R^2 is relatively similar to that of other orders. 


C. 
From the plot graph, I observe that the 10-fold CV average has a "U" shape where the Poloynominal Order 3 has the lowest RMSE value. On the other hand, the all data set has a shape where as the order increases the RMSE value decreases. This may indicates the model on the whole data set is experiencing 'Overfitting' as the order increases. On the other hand, the 10-fold CV average mitigates this over-fitting effect as the order increases. 

D.  
I built my final OLS model by increasing to 15-fold CV but not increasing too much. I'm sticking with the Poloynominal Order 3 since the RSME value is the smallest and the change in R^2 is not big enough to warrant the increasing the Order to decrease the AVG RSME value. 

For Order 1, AVG R^2 is 0.61217641653 and AVG RSME is 13339.3442522
For Order 2, AVG R^2 is 0.633571192535 and AVG RSME is 13196.4000367
For Order 3, AVG R^2 is 0.643196129431 and AVG RSME is 13081.864947
For Order 4, AVG R^2 is 0.644229202189 and AVG RSME is 13251.4983638
For Order 5, AVG R^2 is 0.645372338702 and AVG RSME is 13636.463317
For Order 6, AVG R^2 is 0.646439623008 and AVG RSME is 14791.0454429
For Order 7, AVG R^2 is 0.648364390172 and AVG RSME is 17480.4542803
For Order 8, AVG R^2 is 0.654399062792 and AVG RSME is 19965.8623323
For Order 9, AVG R^2 is 0.663882845858 and AVG RSME is 19880.0463057
For Order 10, AVG R^2 is 0.669678880488 and AVG RSME is 14141.6002027
For Order 11, AVG R^2 is 0.669936457078 and AVG RSME is 13887.3859729
For Order 12, AVG R^2 is 0.671037104935 and AVG RSME is 36957.6082574
For Order 13, AVG R^2 is 0.671552897751 and AVG RSME is 73794.3162013
For Order 14, AVG R^2 is 0.67310284193 and AVG RSME is 133217.872086
For Order 15, AVG R^2 is 0.677160425485 and AVG RSME is 210939.194088


With the model, I have applied on unlabeled data and found following predicted values {datapoint#: [[ population value, predicted incident value]]}. 
I also created a graph with the regressional line. 

{1: [[18540.0, 3231.7011359975395]], 2: [[43341.0, 20020.544315922605]], 3: [[66636.0, 42545.038456186398]], 4: [[39553.0, 16728.866511694541]], 5: [[23570.0, 5545.390497536172]], 6: [[56024.0, 32051.803165197507]], 7: [[28606.0, 8503.8922089934986]], 8: [[1806.0, 1267.9044478562598]], 9: [[10700.0, 1110.8889880091831]], 10: [[3540.0, 1002.1114460292438]], 11: [[9027.0, 919.1944402782766]], 12: [[41104.0, 18053.927814221508]], 13: [[78895.0, 54006.096147435397]], 14: [[19104.0, 3456.4781866123885]], 15: [[17590.0, 2873.8610078696502]], 16: [[24861.0, 6246.0879426272577]], 17: [[7987.0, 849.69692748122213]], 18: [[26999.0, 7495.3859512222971]], 19: [[8690.0, 892.44956802393619]], 20: [[75371.0, 50852.394240499394]], 21: [[12635.0, 1451.7727019999222]], 22: [[59129.0, 35124.086108821517]], 23: [[7926.0, 846.82425300408329]], 24: [[16575.0, 2520.9228743658468]], 25: [[34555.0, 12706.289671283537]], 26: [[47211.0, 23556.759570171391]], 27: [[41356.0, 18272.296948923344]], 28: [[56438.0, 32460.233591873832]], 29: [[38917.0, 16195.328933832991]], 30: [[22922.0, 5209.507040325022]], 31: [[8370.0, 870.79396039196263]], 32: [[1685.0, 1290.9357976113874]], 33: [[67053.0, 42952.786278625397]], 34: [[50502.0, 26672.080080619176]], 35: [[81677.0, 56385.157774765037]], 36: [[14096.0, 1790.9557073539108]], 37: [[87757.0, 61168.206162895629]], 38: [[57311.0, 33322.94114930131]], 39: [[1618.0, 1303.9431120690008]], 40: [[29189.0, 8883.8733852727019]], 41: [[39127.0, 16370.845463850539]], 42: [[58519.0, 34519.227948400105]], 43: [[19168.0, 3482.5580226796692]], 44: [[8176.0, 859.44891386865152]], 45: [[11916.0, 1310.4746824228018]], 46: [[19533.0, 3633.5099586780325]], 47: [[8344.0, 869.19518430633752]], 48: [[9105.0, 925.95777058751025]], 49: [[1858.0, 1258.1881341050221]], 50: [[25590.0, 6659.8491641622641]], 51: [[21902.0, 4702.8040325506017]], 52: [[31834.0, 10697.401491048829]], 53: [[27357.0, 7715.0216380108068]], 54: [[12337.0, 1391.1334006903751]], 55: [[5487.0, 843.71866082369786]], 56: [[38982.0, 16249.586218563805]], 57: [[38780.0, 16081.175739058985]], 58: [[68853.0, 44702.992177540662]], 59: [[9041.0, 920.39254346620612]], 60: [[13779.0, 1711.5107059017032]], 61: [[13393.0, 1619.1276704237314]], 62: [[7823.0, 842.2787356108571]], 63: [[20844.0, 4206.3438510666992]], 64: [[4079.0, 943.63064757312895]], 65: [[17962.0, 3010.8499502725881]], 66: [[80018.0, 54979.183883280915]], 67: [[44837.0, 21368.904722074876]], 68: [[12604.0, 1445.3282593006998]], 69: [[42870.0, 19601.343697976157]], 70: [[85510.0, 59473.615847300942]], 71: [[100820.0, 68882.931187078779]], 72: [[1123.0, 1405.6827198376477]], 73: [[37144.0, 14740.04643437921]], 74: [[40782.0, 17776.126897970033]], 75: [[17329.0, 2780.1786416690484]], 76: [[10170.0, 1039.6490370843994]], 77: [[17045.0, 2680.5343759614252]], 78: [[93386.0, 64977.512394390549]], 79: [[16415.0, 2468.1030916140976]], 80: [[17208.0, 2737.4314369294043]], 81: [[28647.0, 8530.3733947410656]], 82: [[24438.0, 6011.9427220220323]], 83: [[94600.0, 65708.721842645464]], 84: [[34882.0, 12956.8378595262]], 85: [[14992.0, 2032.7477113087207]], 86: [[26883.0, 7424.8490577007051]], 87: [[59283.0, 35276.843370016984]], 88: [[12680.0, 1461.1837330695953]], 89: [[67970.0, 43846.542926767819]], 90: [[34981.0, 13033.062867426612]], 91: [[63393.0, 39352.116289951082]], 92: [[4135.0, 938.20230781502312]], 93: [[5672.0, 836.20084178944342]], 94: [[60035.0, 36022.976944652291]], 95: [[42230.0, 19036.022497626862]], 96: [[40931.0, 17904.502241815469]], 97: [[22658.0, 5075.7584080794659]], 98: [[27655.0, 7900.0693431813106]], 99: [[1224.0, 1384.1147294662865]], 100: [[40730.0, 17731.395071141811]], 101: [[84500.0, 58682.934287634096]], 102: [[20857.0, 4212.260865811937]], 103: [[42252.0, 19055.371621895669]], 104: [[40827.0, 17814.866546527199]], 105: [[7135.0, 821.79790237804571]], 106: [[520.0, 1543.1337431591528]], 107: [[36934.0, 14570.930846079291]], 108: [[78134.0, 53337.462836105216]], 109: [[7895.0, 845.41585188185979]], 110: [[37337.0, 14896.093385007101]], 111: [[61347.0, 37324.855223543098]], 112: [[40113.0, 17203.450074052071]], 113: [[37280.0, 14849.945327683541]], 114: [[45768.0, 22220.239559071299]]}



E. 

I expect the average RMSE of the unlabeled data is 13081.864947 based on my 15-fold CV model with the Polynomial Order of 3. I can improve the performace by having more data points with 1) historical characterics (different time series) that can enable higher fold cross validation and 2) understanding of the more modular characteristics of the incidents to draw more actionable insights, and 3) having a more rigorous regressional models and random incident generation that can create multiple scenarios to test the performance of the model. 










